{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCp1yPtAdOAr",
        "outputId": "c48c0c7a-1325-4536-f5a8-6a61c9f32a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "git version 2.34.1\n"
          ]
        }
      ],
      "source": [
        "!git --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNyQqsn8dgpL",
        "outputId": "73689d58-9b23-40ae-867c-2fda8a384726"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'llm_engineering' already exists and is not an empty directory.\n",
            "/content/llm_engineering\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Clone the repository with sparse checkout enabled\n",
        "!git clone --depth=1 --filter=blob:none --sparse https://github.com/ed-donner/llm_engineering.git\n",
        "\n",
        "# Step 2: Move into the repository\n",
        "%cd llm_engineering\n",
        "\n",
        "# Step 3: Enable sparse checkout & get only \"week5/knowledge-base\"\n",
        "!git sparse-checkout set week5/knowledge-base\n",
        "!git pull\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0miAcrKbZcDx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "# from dotenv import load_dotenv\n",
        "# import gradio as gr\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70g41ppbZgbr"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Set your Gemini API key (assuming it's stored in a variable named `API_KEY`)\n",
        "API_KEY = \"your-api-key\"  # Replace this with your actual key\n",
        "\n",
        "# Configure the Gemini API\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "# Select the model\n",
        "MODEL = \"gemini-1.5-flash\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dGDjF_cZjFn"
      },
      "outputs": [],
      "source": [
        "context = {}\n",
        "\n",
        "employees = glob.glob(\"/content/llm_engineering/week5/knowledge-base/employees/*\")\n",
        "# /content/llm_engineering/week5/knowledge-base/employees\n",
        "for employee in employees:\n",
        "    name = employee.split(' ')[-1][:-3]\n",
        "    doc = \"\"\n",
        "    with open(employee, \"r\", encoding=\"utf-8\") as f:\n",
        "        doc = f.read()\n",
        "    context[name]=doc\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aclbG25JZldG"
      },
      "outputs": [],
      "source": [
        "products = glob.glob(\"/content/llm_engineering/week5/knowledge-base/products/*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gguav7P8Zox9"
      },
      "outputs": [],
      "source": [
        "for product in products:\n",
        "    name = product.split(os.sep)[-1][:-3]\n",
        "    doc = \"\"\n",
        "    with open(product, \"r\", encoding=\"utf-8\") as f:\n",
        "        doc = f.read()\n",
        "    context[name]=doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hinZ03g7Zqqn",
        "outputId": "3a121d6d-043b-4ace-daee-816fb96f6ed1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['Greene', 'Carter', 'Lancaster', 'Bishop', 'Harper', 'Trenton', 'Spencer', 'Tran', 'Blake', 'Chen', 'Thomson', 'Thompson', 'Carllm', 'Markellm', 'Homellm', 'Rellm'])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCzdMfc3Ztpm"
      },
      "outputs": [],
      "source": [
        "system_message = \"You are an expert in answering accurate questions about Insurellm, the Insurance Tech company. Give brief, accurate answers. If you don't know the answer, say so. Do not make anything up if you haven't been provided with relevant context.\"\n",
        "def get_relevant_context(message):\n",
        "    relevant_context = []\n",
        "    for context_title, context_details in context.items():\n",
        "        if context_title.lower() in message.lower():\n",
        "            relevant_context.append(context_details)\n",
        "    return relevant_context\n",
        "\n",
        "# get_relevant_context(\"Who is lancaster?\")\n",
        "def add_context(message):\n",
        "    relevant_context = get_relevant_context(message)\n",
        "    if relevant_context:\n",
        "        message += \"\\n\\nThe following additional context might be relevant in answering this question:\\n\\n\"\n",
        "        for relevant in relevant_context:\n",
        "            message += relevant + \"\\n\\n\"\n",
        "    return message\n",
        "# print(add_context(\"Who is Alex Lancaster?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z_IgLEYaGvO"
      },
      "outputs": [],
      "source": [
        "# !pip install -U langchain-community\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqWhWFOKZ6ms"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-d67jOyaAIA"
      },
      "outputs": [],
      "source": [
        "MODEL\n",
        "db_name = \"vector_db\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srRGiuaPaN88",
        "outputId": "2dd43f4d-95bd-477b-f7b2-1432881af9fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder: /content/llm_engineering/week5/knowledge-base/employees/, Extracted doc_type: employees\n",
            "Folder: /content/llm_engineering/week5/knowledge-base/company/, Extracted doc_type: company\n",
            "Folder: /content/llm_engineering/week5/knowledge-base/contracts/, Extracted doc_type: contracts\n",
            "Folder: /content/llm_engineering/week5/knowledge-base/products/, Extracted doc_type: products\n",
            "{'source': '/content/llm_engineering/week5/knowledge-base/employees/Samantha Greene.md', 'doc_type': 'employees'}\n",
            "{'source': '/content/llm_engineering/week5/knowledge-base/employees/Emily Carter.md', 'doc_type': 'employees'}\n",
            "{'source': '/content/llm_engineering/week5/knowledge-base/employees/Avery Lancaster.md', 'doc_type': 'employees'}\n",
            "{'source': '/content/llm_engineering/week5/knowledge-base/employees/Jordan K. Bishop.md', 'doc_type': 'employees'}\n",
            "{'source': '/content/llm_engineering/week5/knowledge-base/employees/Alex Harper.md', 'doc_type': 'employees'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
        "\n",
        "folders = glob.glob(\"/content/llm_engineering/week5/knowledge-base/*/\")\n",
        "\n",
        "text_loader_kwargs = {'encoding': 'utf-8'}\n",
        "documents = []\n",
        "\n",
        "for folder in folders:\n",
        "    doc_type = os.path.basename(os.path.normpath(folder))  # Fix applied\n",
        "    print(f\"Folder: {folder}, Extracted doc_type: {doc_type}\")  # Debugging step\n",
        "\n",
        "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
        "    folder_docs = loader.load()\n",
        "\n",
        "    for doc in folder_docs:\n",
        "        doc.metadata[\"doc_type\"] = doc_type  # Assign doc_type correctly\n",
        "        documents.append(doc)\n",
        "\n",
        "# Check if doc_type is correctly assigned\n",
        "for doc in documents[:5]:  # Print first 5 docs\n",
        "    print(doc.metadata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_cOOvlRaRVM",
        "outputId": "dc069145-3d10-4755-9d0b-bfb15f666c3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1088, which is longer than the specified 1000\n"
          ]
        }
      ],
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=300)\n",
        "chunks = text_splitter.split_documents(documents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8judXGDaVZx",
        "outputId": "0e59ffc7-fd37-4bbe-fabc-1bce92a57cae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document types found: products, company, employees, contracts\n"
          ]
        }
      ],
      "source": [
        "doc_types = set(chunk.metadata.get('doc_type', 'Unknown') for chunk in chunks)\n",
        "print(f\"Document types found: {', '.join(doc_types)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oai5mbtuah8s"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain openai\n",
        "# !pip install langchain-chroma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub5YhMIbbABU"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain openai langchain-openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e67c0MBaX3q"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import langchain_openai\n",
        "\n",
        "from langchain.schema import Document\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHK4M7E_bkqk",
        "outputId": "cef2e501-a1c8-495c-9082-552474961381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: langchain 0.3.20\n",
            "Uninstalling langchain-0.3.20:\n",
            "  Successfully uninstalled langchain-0.3.20\n",
            "Found existing installation: transformers 4.48.3\n",
            "Uninstalling transformers-4.48.3:\n",
            "  Successfully uninstalled transformers-4.48.3\n",
            "Found existing installation: sentence-transformers 3.4.1\n",
            "Uninstalling sentence-transformers-3.4.1:\n",
            "  Successfully uninstalled sentence-transformers-3.4.1\n",
            "\u001b[33mWARNING: Skipping langchain-huggingface as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# !pip uninstall -y numpy langchain transformers sentence-transformers langchain-huggingface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGlJHugybrW0"
      },
      "outputs": [],
      "source": [
        "# !pip install --no-cache-dir numpy==1.26.4\n",
        "# !pip install --no-cache-dir langchain langchain-huggingface transformers sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sPXbqQlads3"
      },
      "outputs": [],
      "source": [
        "# If you would rather use the free Vector Embeddings from HuggingFace sentence-transformers\n",
        "# Then replace embeddings = OpenAIEmbeddings()\n",
        "# with:\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_5ljB6BbPN0"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(db_name):\n",
        "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npeooaQdd66x",
        "outputId": "80aecf88-d158-4814-b162-49a21673230d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorstore created with 130 documents\n"
          ]
        }
      ],
      "source": [
        "# Create our Chroma vectorstore!\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
        "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi4psKzcd9Sj",
        "outputId": "6bd05462-2e01-461e-c5c9-def74b47eb0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The vectors have 384 dimensions\n"
          ]
        }
      ],
      "source": [
        "# Get one vector and find how many dimensions it has\n",
        "\n",
        "collection = vectorstore._collection\n",
        "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
        "dimensions = len(sample_embedding)\n",
        "print(f\"The vectors have {dimensions:,} dimensions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsRDYOrieAGm"
      },
      "outputs": [],
      "source": [
        "# Prework\n",
        "\n",
        "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
        "vectors = np.array(result['embeddings'])\n",
        "documents = result['documents']\n",
        "doc_types = [metadata['doc_type'] for metadata in result['metadatas']]\n",
        "colors = [['blue', 'green', 'red', 'orange'][['products', 'employees', 'contracts', 'company'].index(t)] for t in doc_types]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "3_bVjOfSeCSE",
        "outputId": "fbb6f867-e19c-4ba7-a300-62577de0a8df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a58eb32d-5ae2-4457-be02-68ce893d5620\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a58eb32d-5ae2-4457-be02-68ce893d5620\")) {                    Plotly.newPlot(                        \"a58eb32d-5ae2-4457-be02-68ce893d5620\",                        [{\"hoverinfo\":\"text\",\"marker\":{\"color\":[\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"orange\",\"orange\",\"orange\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\"],\"opacity\":0.8,\"size\":5},\"mode\":\"markers\",\"text\":[\"Type: employees\\u003cbr\\u003eText: # Samantha Greene\\n\\n## Summary\\n- **Date of Birth:** October 14, 1990\\n- **Job Title:** HR Generalist\\n-...\",\"Type: employees\\u003cbr\\u003eText: ## Annual Performance History\\n- **2020:** Exceeds Expectations  \\n  Samantha Greene demonstrated exce...\",\"Type: employees\\u003cbr\\u003eText: - **2023:** Meets Expectations  \\n  After attending workshops focused on conflict resolution, Samanth...\",\"Type: employees\\u003cbr\\u003eText: - **2023:** Base Salary - $70,000  \\n  Recognized for substantial improvement in employee relations m...\",\"Type: employees\\u003cbr\\u003eText: # HR Record\\n\\n# Emily Carter\\n\\n## Summary\\n- **Date of Birth:** August 12, 1990  \\n- **Job Title:** Acco...\",\"Type: employees\\u003cbr\\u003eText: - **2017-2019:** Marketing Intern  \\n  - Assisted with market research and campaign development for s...\",\"Type: employees\\u003cbr\\u003eText: ## Compensation History\\n| Year | Base Salary | Bonus         | Total Compensation |\\n|------|--------...\",\"Type: employees\\u003cbr\\u003eText: Emily Carter exemplifies the kind of talent that drives Insurellm's success and is an invaluable ass...\",\"Type: employees\\u003cbr\\u003eText: # Avery Lancaster\\n\\n## Summary\\n- **Date of Birth**: March 15, 1985  \\n- **Job Title**: Co-Founder & Ch...\",\"Type: employees\\u003cbr\\u003eText: - **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \\n  Before launching Insur...\",\"Type: employees\\u003cbr\\u003eText: - **2016**: **Meets Expectations**  \\n  Growth continued, though challenges arose in operational effi...\",\"Type: employees\\u003cbr\\u003eText: - **2020**: **Below Expectations**  \\n  The COVID-19 pandemic posed unforeseen operational difficulti...\",\"Type: employees\\u003cbr\\u003eText: - **2023**: **Exceeds Expectations**  \\n  Market leadership was regained with innovative approaches t...\",\"Type: employees\\u003cbr\\u003eText: ## Other HR Notes\\n- **Professional Development**: Avery has actively participated in leadership trai...\",\"Type: employees\\u003cbr\\u003eText: # HR Record\\n\\n# Jordan K. Bishop\\n\\n## Summary\\n- **Date of Birth:** March 15, 1990\\n- **Job Title:** Fro...\",\"Type: employees\\u003cbr\\u003eText: ## Annual Performance History\\n- **2019:** Exceeds Expectations - Continuously delivered high-quality...\",\"Type: employees\\u003cbr\\u003eText: ## Compensation History\\n- **June 2018:** Starting Salary - $85,000\\n- **June 2019:** Salary Increase ...\",\"Type: employees\\u003cbr\\u003eText: ## Other HR Notes\\n- Jordan K. Bishop has been an integral part of club initiatives, including the In...\",\"Type: employees\\u003cbr\\u003eText: # HR Record\\n\\n# Alex Harper\\n\\n## Summary\\n- **Date of Birth**: March 15, 1993  \\n- **Job Title**: Sales ...\",\"Type: employees\\u003cbr\\u003eText: ## Annual Performance History  \\n- **2021**:  \\n  - **Performance Rating**: 4.5\\u002f5  \\n  - **Key Achievem...\",\"Type: employees\\u003cbr\\u003eText: ## Compensation History  \\n- **2021**:  \\n  - **Base Salary**: $55,000  \\n  - **Bonus**: $5,500 (10% of...\",\"Type: employees\\u003cbr\\u003eText: - **Interests**:  \\n  - In Alex's spare time, they enjoy participating in community volunteer program...\",\"Type: employees\\u003cbr\\u003eText: # HR Record\\n\\n# Samuel Trenton\\n\\n## Summary\\n- **Date of Birth:** April 12, 1989  \\n- **Job Title:** Sen...\",\"Type: employees\\u003cbr\\u003eText: - **August 2016 - May 2018:** Junior Data Analyst  \\n  *Started at Insurellm as a Junior Data Analyst...\",\"Type: employees\\u003cbr\\u003eText: - **2021:** Rating: 4.0\\u002f5  \\n  *There was notable improvement in performance. Worked to enhance model...\",\"Type: employees\\u003cbr\\u003eText: - **2020:** Base Salary: $100,000 + Bonus: $8,000  \\n  *Initial compensation as Senior Data Scientist...\",\"Type: employees\\u003cbr\\u003eText: # HR Record\\n\\n# Oliver Spencer\\n\\n## Summary\\n- **Date of Birth**: May 14, 1990  \\n- **Job Title**: Backe...\",\"Type: employees\\u003cbr\\u003eText: ## Annual Performance History\\n- **2018**: **3\\u002f5** - Adaptable team player but still learning to take...\",\"Type: employees\\u003cbr\\u003eText: ## Compensation History\\n- **March 2018**: Initial salary of $80,000.\\n- **July 2019**: Salary increas...\",\"Type: employees\\u003cbr\\u003eText: # HR Record\\n\\n# Emily Tran\\n\\n## Summary\\n- **Date of Birth:** March 18, 1991  \\n- **Job Title:** Digital...\",\"Type: employees\\u003cbr\\u003eText: - **June 2018 - January 2020**: Marketing Coordinator  \\n  - Assisted in the development and executio...\",\"Type: employees\\u003cbr\\u003eText: - **2022**:  \\n  - Performance Rating: Meets Expectations  \\n  - Key Achievements: Enhanced Insurellm'...\",\"Type: employees\\u003cbr\\u003eText: - **2021**:  \\n  - Base Salary: $67,500  \\n  - No bonus due to reallocation of marketing funds during ...\",\"Type: employees\\u003cbr\\u003eText: # HR Record\\n\\n# Jordan Blake\\n\\n## Summary\\n- **Date of Birth:** March 15, 1993  \\n- **Job Title:** Sales...\",\"Type: employees\\u003cbr\\u003eText: ## Annual Performance History\\n- **2021:** First year at Insurellm; achieved 90% of monthly targets. ...\",\"Type: employees\\u003cbr\\u003eText: ## Other HR Notes\\n- Jordan has shown an interest in continuing education, actively participating in ...\",\"Type: employees\\u003cbr\\u003eText: # HR Record\\n\\n# Alex Chen\\n\\n## Summary\\n- **Date of Birth:** March 15, 1990  \\n- **Job Title:** Backend ...\",\"Type: employees\\u003cbr\\u003eText: ## Annual Performance History\\n- **2020:**  \\n  - Completed onboarding successfully.  \\n  - Met expecta...\",\"Type: employees\\u003cbr\\u003eText: - **2023:**  \\n  - Led a major overhaul of the API internal architecture, enhancing security protocol...\",\"Type: employees\\u003cbr\\u003eText: ## Other HR Notes\\n- Participates regularly in Insurellm's Diversity & Inclusion initiatives, champio...\",\"Type: employees\\u003cbr\\u003eText: # HR Record\\n\\n# Alex Thomson\\n\\n## Summary\\n- **Date of Birth:** March 15, 1995  \\n- **Job Title:** Sales...\",\"Type: employees\\u003cbr\\u003eText: ## Annual Performance History  \\n- **2022** - Rated as \\\"Exceeds Expectations.\\\" Alex Thomson achieved ...\",\"Type: employees\\u003cbr\\u003eText: ## Other HR Notes\\n- Alex Thomson is an active member of the Diversity and Inclusion committee at Ins...\",\"Type: employees\\u003cbr\\u003eText: # HR Record\\n\\n# Maxine Thompson\\n\\n## Summary\\n- **Date of Birth:** January 15, 1991  \\n- **Job Title:** ...\",\"Type: employees\\u003cbr\\u003eText: ## Insurellm Career Progression\\n- **January 2017 - October 2018**: **Junior Data Engineer**  \\n  * Ma...\",\"Type: employees\\u003cbr\\u003eText: ## Annual Performance History\\n- **2017**: *Meets Expectations*  \\n  Maxine showed potential in her ro...\",\"Type: employees\\u003cbr\\u003eText: - **2020**: *Meets Expectations*  \\n  Maxine focused on regaining her footing and excelling with tech...\",\"Type: employees\\u003cbr\\u003eText: - **2023**: *Exceeds Expectations*  \\n  Maxine has taken on mentoring responsibilities and is leading...\",\"Type: employees\\u003cbr\\u003eText: ## Other HR Notes\\n- Maxine participated in various company-sponsored trainings related to big data t...\",\"Type: company\\u003cbr\\u003eText: # Careers at Insurellm\\n\\nInsurellm is hiring! We are looking for talented software engineers, data sc...\",\"Type: company\\u003cbr\\u003eText: # Overview of Insurellm\\n\\nInsurellm is an innovative insurance tech firm with 200 employees across th...\",\"Type: company\\u003cbr\\u003eText: # About Insurellm\\n\\nInsurellm was founded by Avery Lancaster in 2015 as an insurance tech startup des...\",\"Type: contracts\\u003cbr\\u003eText: # Contract with Roadway Insurance Inc. for Carllm\\n\\n---\\n\\n## Terms\\n\\n1. **Agreement Effective Date**: T...\",\"Type: contracts\\u003cbr\\u003eText: ---\\n\\n## Renewal\\n\\n1. **Automatic Renewal**: This agreement will automatically renew for an additional...\",\"Type: contracts\\u003cbr\\u003eText: ---\\n\\n## Features\\n\\n1. **Access to Core Features**: Roadway Insurance Inc. will have access to all Pro...\",\"Type: contracts\\u003cbr\\u003eText: ---\\n\\n## Support\\n\\n1. **Technical Support**: Roadway Insurance Inc. will receive priority technical su...\",\"Type: contracts\\u003cbr\\u003eText: # Contract with GreenValley Insurance for Homellm\\n\\n**Contract Date:** October 6, 2023  \\n**Contract N...\",\"Type: contracts\\u003cbr\\u003eText: 3. **Payment:** GreenValley Insurance shall pay a monthly fee of $10,000, due by the 5th of every mo...\",\"Type: contracts\\u003cbr\\u003eText: ---\\n\\n## Features\\n\\nGreenValley Insurance will receive the following features with Homellm:\\n\\n1. **AI-P...\",\"Type: contracts\\u003cbr\\u003eText: 6. **Customer Portal:** A user-friendly portal for their customers for policy and claims management....\",\"Type: contracts\\u003cbr\\u003eText: ---\\n\\n**Signatures:**\\n\\n_________________________________  \\n**[Name]**  \\n**Title**: CEO  \\n**Insurellm,...\",\"Type: contracts\\u003cbr\\u003eText: # Contract with Pinnacle Insurance Co. for Homellm\\n\\n## Terms\\nThis contract (\\\"Contract\\\") is entered i...\",\"Type: contracts\\u003cbr\\u003eText: ## Renewal\\n1. **Renewal Terms**: At the end of the initial term, this Contract shall automatically r...\",\"Type: contracts\\u003cbr\\u003eText: ## Features\\n1. **AI-Powered Risk Assessment**: Utilized for tailored underwriting decisions specific...\",\"Type: contracts\\u003cbr\\u003eText: ## Support\\n1. **Technical Support**: Insurellm shall provide 24\\u002f7 technical support via an email and...\",\"Type: contracts\\u003cbr\\u003eText: # Contract with GreenField Holdings for Markellm\\n\\n**Effective Date:** November 15, 2023  \\n**Contract...\",\"Type: contracts\\u003cbr\\u003eText: ## Renewal\\n1. **Automatic Renewal**: This contract will automatically renew for sequential one-year ...\",\"Type: contracts\\u003cbr\\u003eText: ## Features\\n1. **AI-Powered Matching**: Access to advanced algorithms that connect GreenField Holdin...\",\"Type: contracts\\u003cbr\\u003eText: ## Support\\n1. **Customer Support Access**: The Client will have access to dedicated support through ...\",\"Type: contracts\\u003cbr\\u003eText: **Signatures:**  \\n_________________________                           _________________________  \\n**...\",\"Type: contracts\\u003cbr\\u003eText: # Contract with Greenstone Insurance for Homellm\\n\\n---\\n\\n## Terms\\n\\n1. **Parties**: This Contract (\\\"Agr...\",\"Type: contracts\\u003cbr\\u003eText: 4. **Payment Terms**: \\n   - The Customer shall pay an amount of $10,000 per month for the Standard T...\",\"Type: contracts\\u003cbr\\u003eText: 2. **Renewal Terms Review**: Prior to each renewal, the Provider and Customer will review the terms ...\",\"Type: contracts\\u003cbr\\u003eText: - **Multi-Channel Integration**: Homellm will integrate with the Customer's existing platforms to cr...\",\"Type: contracts\\u003cbr\\u003eText: --- \\n\\n**AGREEMENT SIGNATURES**\\n\\nBy signing below, the parties acknowledge their acceptance of the te...\",\"Type: contracts\\u003cbr\\u003eText: # Contract with Stellar Insurance Co. for Rellm\\n\\n## Terms\\nThis contract is made between **Insurellm*...\",\"Type: contracts\\u003cbr\\u003eText: ### Payment Terms\\nStellar Insurance Co. agrees to pay Insurellm a monthly subscription fee of **$10,...\",\"Type: contracts\\u003cbr\\u003eText: ## Features\\nStellar Insurance Co. will receive access to the following features of the Rellm product...\",\"Type: contracts\\u003cbr\\u003eText: ## Support\\nInsurellm provides Stellar Insurance Co. with the following support services:\\n\\n- **24\\u002f7 T...\",\"Type: contracts\\u003cbr\\u003eText: # Contract with Velocity Auto Solutions for Carllm\\n\\n**Contract Date:** October 1, 2023  \\n**Contract ...\",\"Type: contracts\\u003cbr\\u003eText: ## Renewal\\n\\n1. **Automatic Renewal**: This contract will automatically renew for successive 12-month...\",\"Type: contracts\\u003cbr\\u003eText: 2. **Feature Enhancements**: Velocity Auto Solutions will receive updates to the Carllm product as o...\",\"Type: contracts\\u003cbr\\u003eText: ---\\n\\n**Accepted and Agreed:**  \\n**For Velocity Auto Solutions**  \\nSignature: _____________________  ...\",\"Type: contracts\\u003cbr\\u003eText: # Contract with TechDrive Insurance for Carllm\\n\\n**Contract Date:** October 1, 2024  \\n**Contract Dura...\",\"Type: contracts\\u003cbr\\u003eText: ## Renewal\\n\\n1. **Automatic Renewal**: This contract shall automatically renew for additional one-yea...\",\"Type: contracts\\u003cbr\\u003eText: 2. **System Requirements**: TechDrive Insurance must ensure that their existing systems meet the tec...\",\"Type: contracts\\u003cbr\\u003eText: ---\\n\\n**Signatures:**\\n\\n**Insurellm Representative:**  \\nName: John Smith  \\nTitle: Account Manager  \\nDa...\",\"Type: contracts\\u003cbr\\u003eText: # Contract with BrightWay Solutions for Markellm\\n\\n**Contract Date:** October 5, 2023  \\n**Contract ID...\",\"Type: contracts\\u003cbr\\u003eText: 3. **Service Level Agreement (SLA):**  \\n   Insurellm commits to a 99.9% uptime for the platform with...\",\"Type: contracts\\u003cbr\\u003eText: 2. **Real-Time Quote Availability:**  \\n   Consumers sourced via BrightWay Solutions will receive rea...\",\"Type: contracts\\u003cbr\\u003eText: 2. **Additional Support Services:**  \\n   Technical support for integration and maintenance will be a...\",\"Type: contracts\\u003cbr\\u003eText: # Contract with Belvedere Insurance for Markellm\\n\\n## Terms\\nThis Contract (\\\"Agreement\\\") is made and e...\",\"Type: contracts\\u003cbr\\u003eText: ## Renewal\\n1. **Renewal Terms**: This Agreement may be renewed for additional one-year terms upon mu...\",\"Type: contracts\\u003cbr\\u003eText: ## Features\\n1. **AI-Powered Matching**: Belvedere Insurance will benefit from Markellm's AI-powered ...\",\"Type: contracts\\u003cbr\\u003eText: ## Support\\n1. **Technical Support**: Technical support will be available from 9 AM to 7 PM EST, Mond...\",\"Type: contracts\\u003cbr\\u003eText: **Insurellm, Inc.**  \\nSignature: ______________________  \\nName: [Authorized Signatory]  \\nTitle: [Tit...\",\"Type: contracts\\u003cbr\\u003eText: # Contract with EverGuard Insurance for Rellm: AI-Powered Enterprise Reinsurance Solution\\n\\n**Contrac...\",\"Type: contracts\\u003cbr\\u003eText: 3. **Payment Terms**: EverGuard Insurance agrees to pay Insurellm a monthly fee of $10,000 for the d...\",\"Type: contracts\\u003cbr\\u003eText: 2. **Price Adjustment**: In the event of a renewal, Insurellm reserves the right to adjust the month...\",\"Type: contracts\\u003cbr\\u003eText: 4. **Client Portal Access**: EverGuard Insurance will have access to both client and broker portals,...\",\"Type: contracts\\u003cbr\\u003eText: 4. **Feedback Mechanisms**: EverGuard Insurance is encouraged to provide feedback regarding Rellm’s ...\",\"Type: contracts\\u003cbr\\u003eText: # Contract with Apex Reinsurance for Rellm: AI-Powered Enterprise Reinsurance Solution\\n\\n## Terms\\n\\n1....\",\"Type: contracts\\u003cbr\\u003eText: 4. **Contract Duration**: This Agreement shall commence on [Start Date] and shall remain in effect f...\",\"Type: contracts\\u003cbr\\u003eText: ## Features\\n\\n1. **AI-Driven Analytics**: The Rellm platform will utilize AI algorithms to provide pr...\",\"Type: contracts\\u003cbr\\u003eText: 5. **Dedicated Client Portal**: A portal for the Client will facilitate real-time communication and ...\",\"Type: contracts\\u003cbr\\u003eText: 4. **Escalation Protocol**: Issues that cannot be resolved at the first level of support will be esc...\",\"Type: products\\u003cbr\\u003eText: # Product Summary\\n\\n# Carllm\\n\\n## Summary\\n\\nCarllm is an innovative auto insurance product developed by...\",\"Type: products\\u003cbr\\u003eText: ## Features\\n\\n- **AI-Powered Risk Assessment**: Carllm leverages artificial intelligence to analyze d...\",\"Type: products\\u003cbr\\u003eText: - **Fraud Detection**: The product incorporates advanced analytics to identify potentially fraudulen...\",\"Type: products\\u003cbr\\u003eText: ## Pricing\\n\\nCarllm is offered under a subscription-based pricing model tailored to meet the needs of...\",\"Type: products\\u003cbr\\u003eText: Contact our sales team for a personalized quote and discover how Carllm can transform your auto insu...\",\"Type: products\\u003cbr\\u003eText: ### Q4 2025: AI and Machine Learning Upgrades\\n- Implement next-gen machine learning models for predi...\",\"Type: products\\u003cbr\\u003eText: # Product Summary\\n\\n# Markellm\\n\\n## Summary\\n\\nMarkellm is an innovative two-sided marketplace designed ...\",\"Type: products\\u003cbr\\u003eText: ## Features\\n\\n- **AI-Powered Matching**: Markellm utilizes sophisticated AI algorithms to match consu...\",\"Type: products\\u003cbr\\u003eText: - **Customized Recommendations**: Based on user profiles and preferences, Markellm provides personal...\",\"Type: products\\u003cbr\\u003eText: ## Pricing\\n\\nAt Markellm, we believe in transparency and flexibility. Our pricing structure is design...\",\"Type: products\\u003cbr\\u003eText: ## 2025-2026 Roadmap\\n\\n### Q1 2025\\n- Launch a mobile app version of Markellm, making it even easier f...\",\"Type: products\\u003cbr\\u003eText: ### Q4 2026\\n- Implement machine learning enhancements to our AI algorithm, further increasing the pr...\",\"Type: products\\u003cbr\\u003eText: # Product Summary\\n\\n# Homellm\\n\\n## Summary\\nHomellm is an innovative home insurance product developed b...\",\"Type: products\\u003cbr\\u003eText: ### 2. Dynamic Pricing Model\\nWith Homellm's innovative dynamic pricing model, insurance providers ca...\",\"Type: products\\u003cbr\\u003eText: ### 4. Predictive Maintenance Alerts\\nHomellm incorporates predictive analytics to advise homeowners ...\",\"Type: products\\u003cbr\\u003eText: ### 6. Customer Portal\\nA user-friendly online portal and mobile application enables customers to man...\",\"Type: products\\u003cbr\\u003eText: All tiers include a comprehensive training program and ongoing updates to ensure optimal performance...\",\"Type: products\\u003cbr\\u003eText: With Homellm, Insurellm is committed to transforming the landscape of home insurance, ensuring both ...\",\"Type: products\\u003cbr\\u003eText: # Product Summary\\n\\n# Rellm: AI-Powered Enterprise Reinsurance Solution\\n\\n## Summary\\n\\nRellm is an inno...\",\"Type: products\\u003cbr\\u003eText: ## Features\\n\\n### AI-Driven Analytics\\nRellm utilizes cutting-edge AI algorithms to provide predictive...\",\"Type: products\\u003cbr\\u003eText: ### Risk Assessment Module\\nThe comprehensive risk assessment module within Rellm allows insurers to ...\",\"Type: products\\u003cbr\\u003eText: ### Regulatory Compliance Tools\\nRellm includes built-in compliance tracking features to help organiz...\",\"Type: products\\u003cbr\\u003eText: Join the growing number of organizations leveraging Rellm to enhance their reinsurance processes whi...\",\"Type: products\\u003cbr\\u003eText: - **Q3 2026**: \\n  - Release of a community platform for Rellm users to exchange insights, tips, and ...\"],\"x\":[12.7773905,13.101133,13.361466,12.8676195,9.970374,9.217181,11.959066,10.9030695,5.3489122,5.5364985,5.9530425,5.636863,5.207613,6.970327,6.313981,14.856137,14.405435,5.9251456,8.89876,10.860671,11.619156,8.886166,8.640302,8.710296,12.558609,10.831583,7.076376,14.656927,11.221302,9.277634,9.552641,11.534411,10.59127,8.397142,11.220802,6.28889,7.3983564,14.994328,13.498237,6.056792,8.32191,12.657376,7.6576376,8.324687,10.311122,12.434835,10.409952,10.95546,11.202696,5.435546,2.2162917,3.1629286,-6.3658757,-11.050532,-1.9714707,-4.3589144,-7.2349916,-7.3011365,-3.6091995,-4.4528084,-7.0511703,-8.15671,-10.4526415,-9.551617,-6.185966,-7.662217,-11.081548,-1.5064497,-11.673727,-8.369883,-7.457279,-9.463874,-10.071816,-5.2539186,-7.5708256,-6.640297,-6.6902356,-2.993213,-5.8876643,-6.389258,-5.401355,-5.8130713,-8.3335495,-5.450551,-4.7223573,-4.3398013,-5.3006034,-9.94386,-10.839714,-10.102078,-9.156634,-8.317186,-10.447218,-2.5660553,-6.09627,-6.5336685,-5.0865545,-5.7928295,-4.0556407,-4.4095187,-5.2454906,-5.005198,-10.740521,-2.28018,-3.5000865,-6.3789334,-1.3647543,-1.4502101,-2.0079932,-3.3919322,-1.0207374,-0.37769142,0.20266987,0.0018105011,-0.6388094,-11.27576,1.0903995,0.34264275,-0.019567247,-0.65326285,-0.58342606,-2.3695378,0.04563382,1.1211658,-0.7325156,-1.1189467,-2.2311778,-3.7495506,-1.0691687,-1.9767606],\"y\":[3.0837193,2.1519163,4.253788,3.726694,5.822854,-2.5215974,-0.28116047,-2.0343845,-1.685961,-1.2964168,-0.38489673,-0.4133125,0.38992932,-0.72353005,4.416904,1.8572571,5.7789536,5.2262173,5.676107,5.8854556,5.0751085,4.0957575,1.6728246,1.6421624,5.361169,4.174662,3.5725162,1.6217016,7.851393,-1.1621586,-1.2662109,6.2045746,-0.95492256,6.467592,6.8781605,6.0521526,3.6195142,3.103709,5.6772337,3.1234765,5.3644013,6.6533523,5.283238,8.126838,2.2271364,1.453857,1.8278198,3.034112,1.6648595,2.5730145,-3.529737,-3.1224601,2.135852,-8.394876,0.452661,1.4675517,-4.95489,-5.114319,-2.2472305,-2.338781,-1.1351889,-6.582491,-8.8840475,-5.1444097,-2.054401,-2.2763,-8.998811,-0.018655501,-1.1816187,0.5469484,-4.322981,-7.6977153,-5.2922063,-2.486315,-0.33395293,-7.1586914,-7.1945906,-6.50548,-6.0672584,3.5117352,4.0125947,3.988042,1.2837234,2.2145717,2.859642,2.2279265,1.2105161,-2.6771812,-4.4628406,-2.464594,-1.8936894,-3.3006208,-9.195172,-1.2984066,-1.8831519,-0.27246463,-7.742285,-8.147779,-5.582875,-5.409642,-3.9864542,-7.0863085,-6.4113255,-5.4074144,-4.2905483,-2.943973,2.8501508,2.3603096,1.7956371,0.49579194,1.4795495,1.8035041,-0.60543245,-0.61136985,-1.2071023,-1.1879399,1.1462245,1.30924,-2.891601,-3.3264039,-3.7660518,-3.0627048,-4.3273263,-3.7430077,-6.3845754,-6.49159,-6.7749205,-7.0057673,-7.801826,-7.909674],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"margin\":{\"r\":20,\"b\":10,\"l\":10,\"t\":40},\"title\":{\"text\":\"2D Chroma Vector Store Visualization\"},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}}},\"width\":800,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a58eb32d-5ae2-4457-be02-68ce893d5620');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# We humans find it easier to visalize things in 2D!\n",
        "# Reduce the dimensionality of the vectors to 2D using t-SNE\n",
        "# (t-distributed stochastic neighbor embedding)\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "reduced_vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "# Create the 2D scatter plot\n",
        "fig = go.Figure(data=[go.Scatter(\n",
        "    x=reduced_vectors[:, 0],\n",
        "    y=reduced_vectors[:, 1],\n",
        "    mode='markers',\n",
        "    marker=dict(size=5, color=colors, opacity=0.8),\n",
        "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
        "    hoverinfo='text'\n",
        ")])\n",
        "\n",
        "fig.update_layout(\n",
        "    title='2D Chroma Vector Store Visualization',\n",
        "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
        "    width=800,\n",
        "    height=600,\n",
        "    margin=dict(r=20, b=10, l=10, t=40)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bw3-LhVeFl6"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.llms import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM6_n6m5eLlI"
      },
      "outputs": [],
      "source": [
        "\n",
        "llm = HuggingFaceHub(repo_id=\"EleutherAI/gpt-neo-2.7B\", huggingfacehub_api_token=\"hf-token\")\n",
        "\n",
        "# Set up the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "\n",
        "# The retriever is an abstraction over the VectorStore\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 25})\n",
        "\n",
        "# Create the conversational retrieval chain\n",
        "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYDEE5Cjef82",
        "outputId": "b88e6e47-fdbf-4828-86d1-119e42f0d072"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning:\n",
            "\n",
            "'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "- **2020**: *Meets Expectations*  \n",
            "  Maxine focused on regaining her footing and excelling with technical skills. She was stable, though not standout, in her contributions. Feedback indicated a need for more proactivity.  \n",
            "\n",
            "- **2021**: *Exceeds Expectations*  \n",
            "  Maxine spearheaded the transition to a new data warehousing solution, significantly enhancing Insurellm’s data analytics capabilities. This major achievement bolstered her reputation within the company.  \n",
            "\n",
            "- **2022**: *Outstanding*  \n",
            "  Maxine continued her upward trajectory, successfully implementing machine learning algorithms to predict customer behavior, which was well-received by the leadership team and improved client satisfaction.  \n",
            "\n",
            "- **2023**: *Exceeds Expectations*  \n",
            "  Maxine has taken on mentoring responsibilities and is leading a cross-functional team for data governance initiatives, showcasing her leadership and solidifying her role at Insurellm.\n",
            "\n",
            "## Other HR Notes\n",
            "- Maxine participated in various company-sponsored trainings related to big data technologies and cloud infrastructure.  \n",
            "- She was recognized for her contributions with the “Insurellm Innovator Award” in 2022.  \n",
            "- Maxine is currently involved in the women-in-tech initiative and participates in mentorship programs to guide junior employees.  \n",
            "- Future development areas include improving her stakeholder communication skills to ensure smoother project transitions and collaboration.\n",
            "\n",
            "## Insurellm Career Progression\n",
            "- **January 2017 - October 2018**: **Junior Data Engineer**  \n",
            "  * Maxine joined Insurellm as a Junior Data Engineer, focusing primarily on ETL processes and data integration tasks. She quickly learned Insurellm's data architecture, collaborating with other team members to streamline data workflows.  \n",
            "- **November 2018 - December 2020**: **Data Engineer**  \n",
            "  * In her new role, Maxine expanded her responsibilities to include designing comprehensive data models and improving data quality measures. Though she excelled in technical skills, communication issues with non-technical teams led to some project delays.  \n",
            "- **January 2021 - Present**: **Senior Data Engineer**  \n",
            "  * Maxine was promoted to Senior Data Engineer after successfully leading a pivotal project that improved data retrieval times by 30%. She now mentors junior engineers and is involved in strategic data initiatives, solidifying her position as a valued asset at Insurellm. She was recognized as Insurellm Innovator of the year in 2023, receiving the prestigious IIOTY 2023 award.\n",
            "\n",
            "# Product Summary\n",
            "\n",
            "# Carllm\n",
            "\n",
            "## Summary\n",
            "\n",
            "Carllm is an innovative auto insurance product developed by Insurellm, designed to streamline the way insurance companies offer coverage to their customers. Powered by cutting-edge artificial intelligence, Carllm utilizes advanced algorithms to deliver personalized auto insurance solutions, ensuring optimal coverage while minimizing costs. With a robust infrastructure that supports both B2B and B2C customers, Carllm redefines the auto insurance landscape and empowers insurance providers to enhance customer satisfaction and retention.\n",
            "\n",
            "## Features\n",
            "\n",
            "- **AI-Powered Risk Assessment**: Carllm leverages artificial intelligence to analyze driver behavior, vehicle conditions, and historical claims data. This enables insurers to make informed decisions and set competitive premiums that reflect true risk profiles.\n",
            "\n",
            "## Other HR Notes\n",
            "- Alex Thomson is an active member of the Diversity and Inclusion committee at Insurellm and has participated in various community outreach programs.  \n",
            "- Alex has received external training on advanced CRM usage, which has subsequently improved team efficiency and productivity.\n",
            "- Continuous professional development through attending sales conventions and workshops, with plans to pursue certification in Sales Enablement in 2024.\n",
            "- Recognized by peers for promoting a supportive and high-energy team environment, often organizing team-building activities to enhance camaraderie within the SDR department. \n",
            "\n",
            "--- \n",
            "**Comment:** Alex Thomson is considered a cornerstone of Insurellm’s sales team and has a bright future within the organization.\n",
            "\n",
            "### Q4 2026\n",
            "- Implement machine learning enhancements to our AI algorithm, further increasing the precision and personalization of matches.\n",
            "- Explore international expansion opportunities, launching in select markets outside the US.\n",
            "\n",
            "Markellm is committed to improving the insurance experience for both consumers and providers. By leveraging technology and user insights, we aim to become the leading platform in the insurance marketplace ecosystem. Join us on this exciting journey towards smarter, more efficient insurance solutions!\n",
            "\n",
            "# About Insurellm\n",
            "\n",
            "Insurellm was founded by Avery Lancaster in 2015 as an insurance tech startup designed to disrupt an industry in need of innovative products. It's first product was Markellm, the marketplace connecting consumers with insurance providers.\n",
            "It rapidly expanded, adding new products and clients, reaching 200 emmployees by 2024 with 12 offices across the US.\n",
            "\n",
            "### Q4 2025: AI and Machine Learning Upgrades\n",
            "- Implement next-gen machine learning models for predictive analysis.\n",
            "- Roll out customer insights dashboard updates based on user feedback.\n",
            "\n",
            "### 2026: Scaling and Partnerships\n",
            "- Increase partnerships with automakers for integrated insurance solutions.\n",
            "- Enhance the **AI customer support system** to include multi-language support.\n",
            "\n",
            "Carllm is not just an auto insurance product; it is a transformative tool for the insurance industry. Join us on this exciting journey as we redefine the future of auto insurance with technology and customer-centric solutions.\n",
            "\n",
            "## Other HR Notes\n",
            "- Participates regularly in Insurellm's Diversity & Inclusion initiatives, championing tech accessibility for underrepresented communities.\n",
            "- Completed several certifications in cloud architecture and DevOps, contributing to professional growth.\n",
            "- Plans for a professional development course in AI and machine learning to further enhance backend capabilities in Insurellm's offerings.\n",
            "- Acknowledged for volunteer efforts in local tech meetups, bringing seasoned engineers to mentor aspiring coders.  \n",
            "\n",
            "Alex Chen continues to be a vital asset at Insurellm, contributing significantly to innovative backend solutions that help shape the future of insurance technology.\n",
            "\n",
            "# HR Record\n",
            "\n",
            "# Oliver Spencer\n",
            "\n",
            "## Summary\n",
            "- **Date of Birth**: May 14, 1990  \n",
            "- **Job Title**: Backend Software Engineer  \n",
            "- **Location**: Austin, Texas  \n",
            "\n",
            "## Insurellm Career Progression\n",
            "- **March 2018**: Joined Insurellm as a Backend Developer I, focusing on API development for customer management systems.\n",
            "- **July 2019**: Promoted to Backend Developer II after successfully leading a team project to revamp the claims processing system, reducing response time by 30%.\n",
            "- **June 2021**: Transitioned to Backend Software Engineer with a broader role in architecture and system design, collaborating closely with the DevOps team.\n",
            "- **September 2022**: Assigned as the lead engineer for the new \"Innovate\" initiative, aimed at integrating AI-driven solutions into existing products.\n",
            "- **January 2023**: Awarded a mentorship role to guide new hires in backend technology and best practices within Insurellm.\n",
            "\n",
            "Emily Carter exemplifies the kind of talent that drives Insurellm's success and is an invaluable asset to the company.\n",
            "\n",
            "# HR Record\n",
            "\n",
            "# Alex Chen\n",
            "\n",
            "## Summary\n",
            "- **Date of Birth:** March 15, 1990  \n",
            "- **Job Title:** Backend Software Engineer  \n",
            "- **Location:** San Francisco, California  \n",
            "\n",
            "## Insurellm Career Progression\n",
            "- **April 2020:** Joined Insurellm as a Junior Backend Developer. Focused on building APIs to enhance customer data security.\n",
            "- **October 2021:** Promoted to Backend Software Engineer. Took on leadership for a key project developing a microservices architecture to support the company's growing platform.\n",
            "- **March 2023:** Awarded the title of Senior Backend Software Engineer due to exemplary performance in scaling backend services, reducing downtime by 30% over six months.\n",
            "\n",
            "## Annual Performance History\n",
            "- **2020:**  \n",
            "  - Completed onboarding successfully.  \n",
            "  - Met expectations in delivering project milestones.  \n",
            "  - Received positive feedback from the team leads.\n",
            "\n",
            "## Annual Performance History\n",
            "- **2017**: *Meets Expectations*  \n",
            "  Maxine showed potential in her role but struggled with initial project deadlines. Her adaptability and willingness to learn made positive impacts on her team.  \n",
            "\n",
            "- **2018**: *Exceeds Expectations*  \n",
            "  Maxine improved significantly, becoming a reliable team member with strong problem-solving skills. She took on leadership in a project that automated data entry processes.  \n",
            "\n",
            "- **2019**: *Needs Improvement*  \n",
            "  During this year, difficult personal circumstances affected Maxine's performance. She missed key deadlines and had several communication issues with stakeholders.  \n",
            "\n",
            "- **2020**: *Meets Expectations*  \n",
            "  Maxine focused on regaining her footing and excelling with technical skills. She was stable, though not standout, in her contributions. Feedback indicated a need for more proactivity.\n",
            "\n",
            "# HR Record\n",
            "\n",
            "# Alex Thomson\n",
            "\n",
            "## Summary\n",
            "- **Date of Birth:** March 15, 1995  \n",
            "- **Job Title:** Sales Development Representative (SDR)  \n",
            "- **Location:** Austin, Texas  \n",
            "\n",
            "## Insurellm Career Progression\n",
            "- **November 2022** - Joined Insurellm as a Sales Development Representative. Alex Thomson quickly adapted to the team, demonstrating exceptional communication and rapport-building skills.\n",
            "- **January 2023** - Promoted to Team Lead for special projects due to Alex's initiative in driving B2B customer outreach programs.  \n",
            "- **August 2023** - Developed a training module for new SDRs at Insurellm, enhancing onboarding processes based on feedback and strategies that Alex Thomson pioneered.  \n",
            "- **Current** - Continues to excel in the role, leading a small team of 5 SDRs while collaborating closely with the marketing department to identify new lead-generation strategies.\n",
            "\n",
            "Contact our sales team for a personalized quote and discover how Carllm can transform your auto insurance offerings!\n",
            "\n",
            "## 2025-2026 Roadmap\n",
            "\n",
            "In our commitment to continuous improvement and innovation, Insurellm has outlined the following roadmap for Carllm:\n",
            "\n",
            "### Q1 2025: Launch Feature Enhancements\n",
            "- **Expanded data integrations** for better risk assessment.\n",
            "- **Enhanced fraud detection algorithms** to reduce losses.\n",
            "\n",
            "### Q2 2025: Customer Experience Improvements\n",
            "- Launch of a new **mobile app** for end-users.\n",
            "- Introduction of **telematics-based pricing** to provide even more tailored coverage options.\n",
            "\n",
            "### Q3 2025: Global Expansion\n",
            "- Begin pilot programs for international insurance markets.\n",
            "- Collaborate with local insurers to offer compliant, localized versions of Carllm.\n",
            "\n",
            "### Q4 2025: AI and Machine Learning Upgrades\n",
            "- Implement next-gen machine learning models for predictive analysis.\n",
            "- Roll out customer insights dashboard updates based on user feedback.\n",
            "\n",
            "## Other HR Notes\n",
            "- Jordan K. Bishop has been an integral part of club initiatives, including the Insurellm Code Reviews and Feedback Group, providing peer support.\n",
            "- Active participant in the company's Diversity and Inclusion committee, promoting a positive work culture.\n",
            "- Jordan has expressed interest in professional development courses, particularly those focused on modern web technologies, which are being considered for sponsorship by Insurellm.\n",
            "- Engaged in a 6-month performance improvement plan as of August 2023, focusing on skill development and consistent performance monitoring. \n",
            "\n",
            "Jordan K. Bishop is a valued member of the Insurellm family, exhibiting a commitment to growth and development despite recent challenges.\n",
            "\n",
            "# Product Summary\n",
            "\n",
            "# Rellm: AI-Powered Enterprise Reinsurance Solution\n",
            "\n",
            "## Summary\n",
            "\n",
            "Rellm is an innovative enterprise reinsurance product developed by Insurellm, designed to transform the way reinsurance companies operate. Harnessing the power of artificial intelligence, Rellm offers an advanced platform that redefines risk management, enhances decision-making processes, and optimizes operational efficiencies within the reinsurance industry. With seamless integrations and robust analytics, Rellm enables insurers to proactively manage their portfolios and respond to market dynamics with agility.\n",
            "\n",
            "## Features\n",
            "\n",
            "### AI-Driven Analytics\n",
            "Rellm utilizes cutting-edge AI algorithms to provide predictive insights into risk exposures, enabling users to forecast trends and make informed decisions. Its real-time data analysis empowers reinsurance professionals with actionable intelligence.\n",
            "\n",
            "- **June 2018 - January 2020**: Marketing Coordinator  \n",
            "  - Assisted in the development and execution of marketing campaigns to promote Insurellm's products.\n",
            "  - Collected and analyzed data on customer demographics to inform Insurellm’s marketing strategies.\n",
            "\n",
            "- **January 2017 - May 2018**: Marketing Intern  \n",
            "  - Supported the Marketing team by collaborating on content creation and digital advertising projects.\n",
            "  - Gained hands-on experience with marketing automation tools, enriching her skillset for her role in Insurellm.\n",
            "\n",
            "---\n",
            "\n",
            "## Annual Performance History\n",
            "- **2023**:  \n",
            "  - Performance Rating: Exceeds Expectations  \n",
            "  - Key Achievements: Led the \"Tech the Halls\" campaign that resulted in a 50% increase in leads during the holiday season. \n",
            "  - Emily Tran's innovative strategies and attention to detail have made her stand out among her peers.\n",
            "\n",
            "# Careers at Insurellm\n",
            "\n",
            "Insurellm is hiring! We are looking for talented software engineers, data scientists and account executives to join our growing team. Come be a part of our movement to disrupt the insurance sector.\n",
            "\n",
            "# Product Summary\n",
            "\n",
            "# Markellm\n",
            "\n",
            "## Summary\n",
            "\n",
            "Markellm is an innovative two-sided marketplace designed to seamlessly connect consumers with insurance companies. Powered by advanced matching AI, Markellm transforms the insurance shopping experience, making it more efficient, personalized, and accessible. Whether you're a homeowner searching for the best rates on home insurance or an insurer looking to reach new customers, Markellm acts as the ultimate bridge, delivering tailored solutions for all parties involved. With a user-friendly interface and powerful algorithms, Markellm not only saves time but also enhances decision-making in the often-complex insurance landscape.\n",
            "\n",
            "## Features\n",
            "\n",
            "- **AI-Powered Matching**: Markellm utilizes sophisticated AI algorithms to match consumers with the most suitable insurance products based on their individual needs and preferences. This ensures that both parties get the best possible options.\n",
            "\n",
            "## Features\n",
            "\n",
            "- **AI-Powered Risk Assessment**: Carllm leverages artificial intelligence to analyze driver behavior, vehicle conditions, and historical claims data. This enables insurers to make informed decisions and set competitive premiums that reflect true risk profiles.\n",
            "\n",
            "- **Instant Quoting**: With Carllm, insurance companies can offer near-instant quotes to customers, enhancing the customer experience. The AI engine processes data in real-time, drastically reducing the time it takes to generate quotes.\n",
            "\n",
            "- **Customizable Coverage Plans**: Carllm allows insurers to create flexible and tailored insurance packages based on individual customer needs. This customization improves customer engagement and retention.\n",
            "\n",
            "- **Fraud Detection**: The product incorporates advanced analytics to identify potentially fraudulent claims, significantly reducing the risk of losses for insurance providers.\n",
            "\n",
            "## Features\n",
            "\n",
            "- **AI-Powered Matching**: Markellm utilizes sophisticated AI algorithms to match consumers with the most suitable insurance products based on their individual needs and preferences. This ensures that both parties get the best possible options.\n",
            "\n",
            "- **User-Friendly Interface**: Designed with user experience in mind, Markellm features an intuitive interface that allows consumers to easily browse and compare various insurance offerings from multiple providers.\n",
            "\n",
            "- **Real-Time Quotes**: Consumers can receive real-time quotes from different insurance companies, empowering them to make informed decisions quickly without endless back-and-forth communication.\n",
            "\n",
            "- **Customized Recommendations**: Based on user profiles and preferences, Markellm provides personalized insurance recommendations, ensuring consumers find the right coverage at competitive rates.\n",
            "\n",
            "- **2021**:  \n",
            "  - Base Salary: $67,500  \n",
            "  - No bonus due to reallocation of marketing funds during the pandemic.\n",
            "\n",
            "---\n",
            "\n",
            "## Other HR Notes\n",
            "- **Training Completed**:  \n",
            "  - Advanced Digital Marketing Workshop (2021)  \n",
            "  - Analytics and Reporting in Digital Advertising (2022)\n",
            "\n",
            "- **Professional Development Goals**:  \n",
            "  - Emily Tran aims to become a Marketing Manager within the next two years, focusing on leading larger campaigns and developing junior team members.\n",
            "\n",
            "- **Hobbies**:  \n",
            "  - Emily enjoys photography and regularly contributes to Insurellm's social media content with her own high-quality images.\n",
            "  - She is also passionate about sustainability and organizes monthly team volunteer events for environmental awareness. \n",
            "\n",
            "---\n",
            "\n",
            "Emily Tran continues to be a valuable asset to Insurellm, driving innovative marketing strategies that resonate with a diverse customer base. Her contributions have significantly enhanced the company's branding and customer outreach efforts.\n",
            "\n",
            "# Avery Lancaster\n",
            "\n",
            "## Summary\n",
            "- **Date of Birth**: March 15, 1985  \n",
            "- **Job Title**: Co-Founder & Chief Executive Officer (CEO)  \n",
            "- **Location**: San Francisco, California  \n",
            "\n",
            "## Insurellm Career Progression\n",
            "- **2015 - Present**: Co-Founder & CEO  \n",
            "  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \n",
            "\n",
            "- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \n",
            "  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.\n",
            "\n",
            "- **Interests**:  \n",
            "  - In Alex's spare time, they enjoy participating in community volunteer programs, particularly those focused on financial literacy.  \n",
            "  - Alex is also an avid runner and has participated in several charity marathons.  \n",
            "\n",
            "- **Feedback from HR**:  \n",
            "  - Alex Harper is noted for their work ethic, positive attitude, and willingness to go above and beyond for both clients and colleagues. Recognized for fostering a team spirit within the SDR team.\n",
            "\n",
            "Question: whos averi\n",
            "Helpful Answer: Avery Lancaster\n"
          ]
        }
      ],
      "source": [
        "query = \"whos averi\"\n",
        "result = conversation_chain.invoke({\"question\":query})\n",
        "print(result[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANMSZHzLhg8V"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "\n",
        "# putting it together: set up the conversation chain with the GPT 4o-mini LLM, the vector store and memory\n",
        "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1BRmiJuhi0w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eT89IcA8fis9"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B_n2a3-DejSi",
        "outputId": "ca612307-5880-43db-a69d-d5da25906378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://f2e83dc0d08dc0b918.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://f2e83dc0d08dc0b918.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning:\n",
            "\n",
            "'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning:\n",
            "\n",
            "'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning:\n",
            "\n",
            "'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning:\n",
            "\n",
            "'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning:\n",
            "\n",
            "'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning:\n",
            "\n",
            "'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning:\n",
            "\n",
            "'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def chat(message, history):\n",
        "    result = conversation_chain.invoke({\"question\": message})\n",
        "    return result[\"answer\"]\n",
        "# And in Gradio:\n",
        "\n",
        "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True,debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QeJPm-bfhSR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}